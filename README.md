# Hate-Speech-Detection
The project develops and tests 6 models (Logistic Regression, Multinomial Naive Bayes, Bernoulli Naive Bayes, Random Forest, Ensemble Model, LSTM Model) that can accurately identify and classify instances of hate speech, offensive language, and non-offensive content in textual data, such as social media posts or online comments.
